{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4369ad76-d8b1-45cc-8338-c7b3611a4330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes : ['Adelie Penguin', 'Chinstrap Penguin', 'Emperor Penguin', 'Gentoo Penguin']\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.3625 Acc: 0.3377\n",
      "val Loss: 1.1548 Acc: 0.5333\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.8794 Acc: 0.7565\n",
      "val Loss: 0.7755 Acc: 0.7778\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.5150 Acc: 0.8848\n",
      "val Loss: 0.5430 Acc: 0.8444\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.3245 Acc: 0.9607\n",
      "val Loss: 0.3935 Acc: 0.8889\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.2008 Acc: 0.9791\n",
      "val Loss: 0.3152 Acc: 0.8889\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.1384 Acc: 0.9869\n",
      "val Loss: 0.2982 Acc: 0.8889\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.1136 Acc: 0.9948\n",
      "val Loss: 0.3020 Acc: 0.8889\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.1003 Acc: 0.9948\n",
      "val Loss: 0.3003 Acc: 0.8889\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0876 Acc: 0.9921\n",
      "val Loss: 0.3053 Acc: 0.8889\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0872 Acc: 0.9921\n",
      "val Loss: 0.3016 Acc: 0.8889\n",
      "Entraînement terminé en 5m 28s\n",
      "Meilleure précision en validation : 0.8889\n",
      "Modèle sauvegardé sous 'best_penguin_model.pth'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/elamine/Desktop/ML/path_to_your_image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 144\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Exemple d'utilisation\u001b[39;00m\n\u001b[1;32m    143\u001b[0m test_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Remplacez par le chemin de votre image\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m \u001b[43mpredict_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 124\u001b[0m, in \u001b[0;36mpredict_image\u001b[0;34m(image_path, model, class_names)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_image\u001b[39m(image_path, model, class_names):\n\u001b[1;32m    123\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 124\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     transform \u001b[38;5;241m=\u001b[39m data_transforms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    126\u001b[0m     image \u001b[38;5;241m=\u001b[39m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/elamine/Desktop/ML/path_to_your_image.jpg'"
     ]
    }
   ],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn  # Contient des modules pour construire le modèle\n",
    "import torch.optim as optim  # Contient des algorithmes d'optimisation comme SGD\n",
    "from torchvision import datasets, transforms, models  # Pour charger des données, appliquer des transformations, et utiliser des modèles préentraînés\n",
    "from torch.utils.data import DataLoader  # Pour gérer les batchs de données\n",
    "from torch.optim import lr_scheduler  # Scheduler pour ajuster dynamiquement le taux d'apprentissage\n",
    "from PIL import Image  # Pour charger et manipuler des images\n",
    "\n",
    "# 1. Préparer les données\n",
    "# Définir les transformations pour l'ensemble d'entraînement, validation et test\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Redimensionne les images à 224x224 pixels\n",
    "        transforms.RandomHorizontalFlip(),  # Augmentation : flip horizontal aléatoire pour diversifier les données\n",
    "        transforms.ToTensor(),  # Convertit l'image en tenseur PyTorch\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalisation pour correspondre aux modèles préentraînés\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Même taille que l'entraînement pour cohérence\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Définir le chemin des données\n",
    "data_dir = 'outputQDP'\n",
    "\n",
    "# Charger les ensembles de données d'entraînement, validation et test\n",
    "image_datasets = {x: datasets.ImageFolder(\n",
    "    root=os.path.join(data_dir, x),  # Chemin pour chaque ensemble (train, val, test)\n",
    "    transform=data_transforms[x]  # Appliquer les transformations appropriées\n",
    ") for x in ['train', 'val', 'test']}\n",
    "\n",
    "# Créer des DataLoaders pour gérer les données par batch\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=(x == 'train'))\n",
    "               for x in ['train', 'val', 'test']}\n",
    "\n",
    "# Calculer la taille de chaque ensemble de données\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes  # Obtenir les noms des classes\n",
    "print(f\"Classes : {class_names}\")\n",
    "\n",
    "# 2. Définir le modèle\n",
    "# Importation des poids préentraînés pour ResNet18\n",
    "from torchvision.models import ResNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
